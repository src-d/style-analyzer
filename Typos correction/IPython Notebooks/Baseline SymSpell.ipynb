{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import itertools\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import pysymspell.symspell as symspell\n",
    "from typos_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DISTANCE = 2\n",
    "\n",
    "class Baseline():\n",
    "    \"\"\"\n",
    "    Typos correction model, based on SymSpell lookout algorithm\n",
    "    \n",
    "    https://github.com/wolfgarbe/SymSpell\n",
    "    \n",
    "    and simple Random Forest classifier, based on token frequencies\n",
    "    and edit distance between typo and candidate.\n",
    "    \n",
    "    Requires file containing tokens frequencies in a format 'token, frequency'.\n",
    "    \n",
    "    Training data: dataframe indexed by 'id' and containing columns 'identifier', 'typo'.\n",
    "    Testing data: dataframe indexed by 'id' and containing column 'typo'.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, freq_file):\n",
    "        self.checker = symspell.SymSpell(max_dictionary_edit_distance=MAX_DISTANCE)\n",
    "        self.checker.load_dictionary(freq_file)\n",
    "        self.frequencies = read_frequencies(freq_file)\n",
    "           \n",
    "    def fit(self, train_file, cand_file=None, dump_file=None):\n",
    "        train_df = pandas.read_pickle(train_file)\n",
    "        self.identifiers = train_df.identifier.copy()\n",
    "        \n",
    "        if cand_file is None:\n",
    "            self.candidates = self._create_candidates(train_df, 'cand_' + train_file)\n",
    "        else:\n",
    "            self.candidates = pandas.read_pickle(cand_file)\n",
    "            \n",
    "        self.train_matrix = self._create_matrix(self.candidates)\n",
    "        self.train_labels = self._create_labels()\n",
    "        self.model = RandomForestClassifier()\n",
    "        \n",
    "        self.model.fit(self.train_matrix, self.train_labels)\n",
    "        \n",
    "        if dump_file is not None:\n",
    "            with open(dump_file, 'wb') as f:\n",
    "                pickle.dump(self, f)\n",
    "        \n",
    "    def suggest(self, test_file, cand_file=None):\n",
    "        test_df = pandas.read_pickle(test_file)\n",
    "        if cand_file is None:\n",
    "            test_candidates = self._create_candidates(test_df, 'cand_' + test_file)\n",
    "        else:\n",
    "            test_candidates = pandas.read_pickle(cand_file)\n",
    "            \n",
    "        test_matrix = self._create_matrix(test_candidates)\n",
    "        test_proba = self.model.predict_proba(test_matrix)\n",
    "        return suggest_corrections(test_candidates, test_proba[:, 1])\n",
    "    \n",
    "    def correct(self, test_file, cand_file=None):\n",
    "        return correct(self.suggest(test_file, cand_file))\n",
    "            \n",
    "    def _freq(token):\n",
    "        try:\n",
    "            return self.frequencies[token]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "                \n",
    "    def _create_candidates(self, data, cand_file):\n",
    "        candidates = pandas.DataFrame(columns=['id', 'typo', 'candidate', 'typo_freq', 'cand_freq', 'distance'])\n",
    "        for id, row in tqdm(data.iterrows()):\n",
    "            last_dist = -1\n",
    "            typo = row.typo\n",
    "            for suggestion in checker.lookup(typo, 2, MAX_DISTANCE):\n",
    "                if suggestion.distance != last_dist:\n",
    "                    candidate = suggestion.term\n",
    "                    candidates = candidates.append(pandas.DataFrame([[id, typo, candidate, freq(typo), \n",
    "                                                                      freq(candidate), suggestion.distance]], \n",
    "                                                                    columns=candidates.columns), ignore_index=True)\n",
    "                    last_dist = suggestion.distance\n",
    "\n",
    "            if last_dist == -1:\n",
    "                candidates = candidates.append(pandas.DataFrame([[id, typo, typo, freq(typo), freq(typo), 0]], \n",
    "                                                                columns=candidates.columns), ignore_index=True)\n",
    "        candidates.to_pickle(cand_file)\n",
    "        return candidates\n",
    "        \n",
    "        \n",
    "    def _create_labels(self):\n",
    "        labels = []\n",
    "        for ind, row in self.candidates.iterrows():\n",
    "            labels.append(int(row.candidate == self.identifiers[row.id]))\n",
    "            \n",
    "        return numpy.array(labels)\n",
    "    \n",
    "    def _create_matrix(self, candidates):\n",
    "        return numpy.array(candidates.loc[:, ['typo_freq', 'cand_freq', 'distance']], dtype='int')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTION SCORE\n",
      "\n",
      "{'tn': 2303, 'fn': 543, 'tp': 1734, 'fp': 94}\n",
      "Accuracy: 0.863714163457424\n",
      "Precision: 0.9485776805251641\n",
      "Recall: 0.761528326745718\n",
      "F1: 0.8448233861144945\n",
      "\n",
      "FIRST SUGGESTION SCORE\n",
      "\n",
      "{'tn': 2303, 'fn': 944, 'tp': 1333, 'fp': 94}\n",
      "Accuracy: 0.7779204107830552\n",
      "Precision: 0.9341275402943238\n",
      "Recall: 0.585419411506368\n",
      "F1: 0.7197624190064795\n",
      "\n",
      "FIRST TWO SUGGESTIONS SCORE\n",
      "\n",
      "{'tn': 2396, 'fn': 763, 'tp': 1514, 'fp': 1}\n",
      "Accuracy: 0.8365425759520753\n",
      "Precision: 0.9993399339933994\n",
      "Recall: 0.6649099692577953\n",
      "F1: 0.7985232067510549\n",
      "\n",
      "FIRST THREE SUGGESTIONS SCORE\n",
      "\n",
      "{'tn': 2397, 'fn': 760, 'tp': 1517, 'fp': 0}\n",
      "Accuracy: 0.8373983739837398\n",
      "Precision: 1.0\n",
      "Recall: 0.6662274923144489\n",
      "F1: 0.7996837111228255\n"
     ]
    }
   ],
   "source": [
    "baseline = Baseline('frequencies.csv')\n",
    "baseline.fit('train_c_15k_data.pkl', 'cand_train_c_15k_data.pkl', 'baseline_11k.pkl')\n",
    "baseline_suggestions = baseline.suggest('test_c_15k_data.pkl', 'cand_test_c_15k_data.pkl')\n",
    "\n",
    "print_suggestion_results(pandas.read_pickle('test_c_15k_data.pkl'), baseline_suggestions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
