{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "* tokenization of code\n",
    "* sliding window to create features and labels\n",
    "* use sequence of tokens as X, next token as Y\n",
    "* train model (RF/DT in the beginning))\n",
    "* apply model to find interesting places in repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import bblfsh\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"/path/to/js/repo/**/*.js\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:09<00:00, 19.04it/s]\n",
      "100%|██████████| 187/187 [00:00<00:00, 24943.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# collect filenames with full path\n",
    "files = glob.glob(project, recursive=True)\n",
    "\n",
    "# extract UASTs\n",
    "client = bblfsh.BblfshClient(\"0.0.0.0:9432\")\n",
    "uasts = []\n",
    "final_files = []  # only files where UAST can be extracted\n",
    "for file in tqdm(files):\n",
    "    res = client.parse(file)\n",
    "    if res.status == 0:\n",
    "        uasts.append(res.uast)\n",
    "        final_files.append(file)\n",
    "\n",
    "# read contents of files\n",
    "contents = []\n",
    "for file in tqdm(final_files):\n",
    "    with open(file, \"r\") as f:\n",
    "        contents.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import _____ from _______;\n",
      "\n",
      "export default function() {\n",
      "  const __________ = _____(\n",
      "    {\n",
      "      ______: {\n",
      "        ______: _______.___._____________ || ___________\n",
      "      }\n",
      "    }\n",
      "  );\n",
      "  return function ____(___, ___, ____) {\n",
      "\n",
      "    const ____ = ___.____._____(___)[_];\n",
      "    if (________________.____(____)) {\n",
      "      return ____();\n",
      "    }\n",
      "    return __________(___, ___, ____);\n",
      "  };\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "\n",
    "print(transform_content(contents[n], uasts[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On input\n",
    "* content\n",
    "* uast\n",
    "## Process\n",
    "* ordered_nodes -> list of nodes\n",
    "* select gapes between nodes\n",
    "* split gapes into whitespaces/newlines/etc and keywords/operators\n",
    "* create one list with all elements - nodes, whitespaces/newlines/etc, keywords/operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+\n",
      "import csurf from csurf;\n",
      "\n",
      "export default function() {\n",
      "  const protection = csurf(\n",
      "    {\n",
      "      cookie: {\n",
      "        domain: process.env.COOKIE_DOMAIN || localhost\n",
      "      }\n",
      "    }\n",
      "  );\n",
      "  return function csrf(req, res, next) {\n",
      "\n",
      "    const path = req.path.split(/)[1];\n",
      "    if (.test(path)) {\n",
      "      return next();\n",
      "    }\n",
      "    return protection(req, res, next);\n",
      "  };\n",
      "}\n",
      "\n",
      "-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+\n",
      "import csurf from 'csurf';\n",
      "\n",
      "export default function() {\n",
      "  const protection = csurf(\n",
      "    {\n",
      "      cookie: {\n",
      "        domain: process.env.COOKIE_DOMAIN || 'localhost'\n",
      "      }\n",
      "    }\n",
      "  );\n",
      "  return function csrf(req, res, next) {\n",
      "\n",
      "    const path = req.path.split('/')[1];\n",
      "    if (/(api|external)/.test(path)) {\n",
      "      return next();\n",
      "    }\n",
      "    return protection(req, res, next);\n",
      "  };\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = node_extraction(contents[n], uasts[n])\n",
    "new_res = []\n",
    "for i in res:\n",
    "    if isinstance(i.node, str):\n",
    "        new_res.append(i.node)\n",
    "    else:\n",
    "        new_res.append(i.node.token)\n",
    "print(\"-=+\" * 20)\n",
    "print(\"\".join(new_res))\n",
    "print(\"-=+\" * 20)\n",
    "print(contents[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import common\n",
    "reload(common)\n",
    "\n",
    "from js_reserved import JS_RESERVED\n",
    "\n",
    "\n",
    "Node, prepare_nodes, transform_content = common.Node, common.prepare_nodes, common.transform_content\n",
    "node_extraction = common.node_extraction\n",
    "collect_unique_features = common.collect_unique_features\n",
    "feature_extraction = common.feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"min_samples_split\": 40, \"min_samples_leaf\": 40,\n",
    "          \"criterion\": \"gini\"}\n",
    "\n",
    "\n",
    "def train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, seq_len=5, depth=5,\n",
    "                   use_parents=True):\n",
    "    features, labels, metadata = feature_extraction(final_files, contents, uasts, seq_len=seq_len,\n",
    "                                                    use_features_after=use_features_after, depth=depth,\n",
    "                                                    use_parents=use_parents)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    print(\"Features shape:\", features.shape)\n",
    "    X_tr, X_val, y_tr, y_val, meta_tr, meta_val = train_test_split(features, labels, metadata, random_state=1989)\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier(**dt_params)\n",
    "\n",
    "    clf = clf.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"train:\", accuracy_score(clf.predict(X_tr), y_tr))\n",
    "    print(\"val:\", accuracy_score(clf.predict(X_val), y_val))\n",
    "    \n",
    "    data = {\"X_tr\": X_tr, \"X_val\": X_val, \"y_tr\": y_tr, \"y_val\": y_val, \"meta_tr\": meta_tr,\n",
    "            \"meta_val\": meta_val, \"features\": features, \"labels\": labels, \n",
    "            \"metadata\": metadata}\n",
    "    \n",
    "    l_cnter = defaultdict(int)\n",
    "    for l in labels:\n",
    "        l_cnter[l] += 1\n",
    "    print(l_cnter)\n",
    "    return clf, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 32.56it/s]\n",
      "187it [00:26,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (268367, 70)\n",
      "train: 0.9817712085455222\n",
      "val: 0.9801019495617957\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, seq_len=5, \n",
    "                           depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 31.39it/s]\n",
      "187it [00:19,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (268367, 40)\n",
      "train: 0.9454378338094647\n",
      "val: 0.9406039468192929\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=False, seq_len=5, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 31.51it/s] \n",
      "187it [00:12, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (268367, 20)\n",
      "train: 0.9834902496584276\n",
      "val: 0.9823078757526977\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, use_parents=False,\n",
    "                   seq_len=5, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 32.33it/s]\n",
      "187it [00:10, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (269859, 6)\n",
      "train: 0.9650829570046543\n",
      "val: 0.9630771511153932\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, use_parents=True,\n",
    "                   seq_len=1, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 33.80it/s] \n",
      "187it [00:12, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (269485, 16)\n",
      "train: 0.98478079094368\n",
      "val: 0.983346197233272\n",
      "defaultdict(<class 'int'>, {0: 175905, 1: 75575, 2: 9920, 3: 4175, 4: 3910})\n"
     ]
    }
   ],
   "source": [
    "clf, data = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, \n",
    "                           use_parents=True, seq_len=2, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 33.73it/s] \n",
      "187it [00:10, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (269485, 8)\n",
      "train: 0.9844245545808533\n",
      "val: 0.9830196520809832\n",
      "defaultdict(<class 'int'>, {0: 175905, 1: 75575, 2: 9920, 3: 4175, 4: 3910})\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, \n",
    "                           use_parents=False, seq_len=2, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tl;Dr - couple of tokens before & after prediction spot + parent info gives the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc519cca908>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAUwA4QMFET5QEOEDBRE+UNC/AWZc85xe958nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc50a594cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(data[\"y_val\"], clf.predict(data[\"X_val\"]))\n",
    "\n",
    "plt.matshow(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        nope       0.99      0.99      0.99     43877\n",
      "  whitespace       0.98      0.98      0.98     19039\n",
      "     newline       0.93      0.94      0.94      2402\n",
      "newline_incr       0.91      0.83      0.87      1027\n",
      "newline_decr       0.87      0.80      0.83      1027\n",
      "\n",
      " avg / total       0.98      0.98      0.98     67372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [\"nope\", \"whitespace\", \"newline\", \"newline_incr\", \"newline_decr\"]\n",
    "print(classification_report(data[\"y_val\"], clf.predict(data[\"X_val\"]), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_proba = clf.predict_proba(data[\"X_val\"])\n",
    "max_pred = np.argmax(predictions_proba, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(data[\"X_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67372,)\n"
     ]
    }
   ],
   "source": [
    "max_predictions = predictions_proba[np.arange(max_pred.shape[0]), max_pred]\n",
    "print(max_predictions.shape)\n",
    "sorted_ind = np.argsort(max_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITE = \"\\033[0m\"\n",
    "RED = \"\\033[31m\"\n",
    "GREEN = \"\\033[32m\"\n",
    "ORANGE = \"\\033[33m\"\n",
    "BLUE = \"\\033[34m\"\n",
    "PURPLE = \"\\033[35m\"\n",
    "\n",
    "\n",
    "def visualize_content(meta, context_chars=100):\n",
    "    file, start, end, l_start, l_end = meta\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # surrounding context\n",
    "    print(content[max(0, start - context_chars):start], end=\"\")\n",
    "    # context before label\n",
    "    cprint(content[start:l_start], \"red\", \"on_white\", end=\"\")\n",
    "    # label\n",
    "    cprint(content[l_start:l_end], \"blue\", \"on_yellow\", end=\"\")\n",
    "    # context after label\n",
    "    cprint(content[l_end:end], \"red\", \"on_white\", end=\"\")\n",
    "    # surrounding context\n",
    "    print(content[end:min(len(content), end + context_chars)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m\u001b[31masdas\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored, cprint\n",
    "cprint(\"asdas\", \"red\", \"on_green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('/home/egor/workspace/tmp/freeCodeCamp/common/models/user.js',\n",
       "  21932,\n",
       "  21946,\n",
       "  21934,\n",
       "  21941),\n",
       " 'newline',\n",
       " 'whitespace')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = sorted_ind[0]\n",
    "data[\"meta_val\"][n], target_names[data[\"y_val\"][n]], target_names[predictions[n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateData.$push.progressTimestamps = {\n",
      "            $each: points.map(() => Date.now())\n",
      "          };\n",
      "        }\n",
      "        return this.update$(updateData);\n",
      "      })\n",
      "      .doOnNext(() => this.manualReload()\u001b[47m\u001b[31m )\u001b[0m\u001b[43m\u001b[34m\n",
      "      \u001b[0m\u001b[47m\u001b[31m.map(\u001b[0m() => dedent`\n",
      "        Your projects have been updated.\n",
      "      `);\n",
      "  };\n",
      "\n",
      "  User.prototype.updateMyProfileUI = function updateMyProfileUI(profileUI) {\n",
      "    const oldUI = { ...this.profileUI };\n",
      "    const u\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/egor/workspace/tmp/freeCodeCamp/server/boot/challenge.js', 7181, 7197, 7189, 7194) GT newline_decr , pred whitespace\n"
     ]
    }
   ],
   "source": [
    "n = sorted_ind[1]\n",
    "print(data[\"meta_val\"][n], \"GT\", target_names[data[\"y_val\"][n]], \", pred\", target_names[predictions[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate.now();\n",
      "\n",
      "    if (\n",
      "      !completedChallenge.solution ||\n",
      "      // only basejumps require github links\n",
      "      (\n",
      "        completedChallenge.challengeType === 4 &&\n",
      "        !completedChallenge.githubLink\u001b[47m\u001b[31m\n",
      "      )\u001b[0m\u001b[43m\u001b[34m\n",
      "    \u001b[0m\u001b[47m\u001b[31m) {\u001b[0m\n",
      "      req.flash(\n",
      "        'danger',\n",
      "        'You haven\\'t supplied the necessary URLs for us to inspect your work.'\n",
      "      );\n",
      "      return res.sendStatus(403);\n",
      "    }\n",
      "\n",
      "\n",
      "    return user.getCompletedChall\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/egor/workspace/tmp/freeCodeCamp/server/boot/certificate.js', 5495, 5507, 5501, 5504) GT newline_decr , pred whitespace\n"
     ]
    }
   ],
   "source": [
    "n = sorted_ind[2]\n",
    "print(data[\"meta_val\"][n], \"GT\", target_names[data[\"y_val\"][n]], \", pred\", target_names[predictions[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms.username}/legacy-data-visualization`\n",
      "    )\n",
      "  );\n",
      "\n",
      "  router.get(\n",
      "    '/:username/back-end-certification',\n",
      "    (req, res) => res.redirect(\n",
      "      `/certification/${req.params.username}/legacy-back-end`\u001b[47m\u001b[31m\n",
      "    )\u001b[0m\u001b[43m\u001b[34m\n",
      "  \u001b[0m\u001b[47m\u001b[31m);\n",
      "\u001b[0m\n",
      "  router.get(\n",
      "    '/:username/full-stack-certification',\n",
      "    (req, res) => res.redirect(\n",
      "      `/certification/${req.params.username}/legacy-full-stack`\n",
      "    )\n",
      "  );\n",
      "\n",
      "  router.post(\n",
      "    '/certificate/v\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/egor/workspace/tmp/freeCodeCamp/common/app/Flash/redux/index.js', 1094, 1121, 1103, 1114) GT nope , pred newline\n"
     ]
    }
   ],
   "source": [
    "n = sorted_ind[100]\n",
    "print(data[\"meta_val\"][n], \"GT\", target_names[data[\"y_val\"][n]], \", pred\", target_names[predictions[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      [types.clickOnClose]: _.tail,\n",
      "      [types.fetchMessages.complete]: (state, { payload }) => [\n",
      "        ...state,\n",
      "        ...utils.expressToStack(payload)\n",
      "      ]\n",
      "    }),\n",
      "    defaultState,\n",
      "  ),\n",
      "  \u001b[47m\u001b[31mfunction \u001b[0m\u001b[43m\u001b[34mmetaReducer\u001b[0m\u001b[47m\u001b[31m(state \u001b[0m= defaultState, action) {\n",
      "    if (utils.isFlashAction(action)) {\n",
      "      const { payload } = utils.getFlashAction(action);\n",
      "      return [\n",
      "        ...state,\n",
      "        ...payload\n",
      "      ];\n",
      "    }\n",
      "    return s\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
