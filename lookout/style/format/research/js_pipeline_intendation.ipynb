{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "* tokenization of code\n",
    "* sliding window to create features and labels\n",
    "* use sequence of tokens as X, next token as Y\n",
    "* train model (RF/DT in the beginning))\n",
    "* apply model to find interesting places in repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import bblfsh\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'freeCodeCamp'...\n",
      "remote: Counting objects: 589, done.\u001b[K\n",
      "remote: Compressing objects: 100% (528/528), done.\u001b[K\n",
      "remote: Total 589 (delta 36), reused 287 (delta 13), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (589/589), 1.60 MiB | 1.05 MiB/s, done.\n",
      "Resolving deltas: 100% (36/36), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth=1 --single-branch https://github.com/freeCodeCamp/freeCodeCamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"freeCodeCamp/**/*.js\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:09<00:00, 22.56it/s]\n",
      "100%|██████████| 208/208 [00:00<00:00, 36452.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# collect filenames with full path\n",
    "files = glob.glob(project, recursive=True)\n",
    "\n",
    "# extract UASTs\n",
    "client = bblfsh.BblfshClient(\"0.0.0.0:9432\")\n",
    "uasts = []\n",
    "final_files = []  # only files where UAST can be extracted\n",
    "for file in tqdm(files):\n",
    "    res = client.parse(file)\n",
    "    if res.status == 0:\n",
    "        uasts.append(res.uast)\n",
    "        final_files.append(file)\n",
    "\n",
    "# read contents of files\n",
    "contents = []\n",
    "for file in tqdm(final_files):\n",
    "    with open(file, \"r\") as f:\n",
    "        contents.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import { _____ } from _________;\n",
      "\n",
      "export { _______ } from _______________;\n",
      "\n",
      "export const ______ = {\n",
      "  [_____.______________]: ____________\n",
      "};\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from common import transform_content, extract_nodes\n",
    "\n",
    "n = 50\n",
    "\n",
    "print(transform_content(contents[n], uasts[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On input\n",
    "* content\n",
    "* uast\n",
    "## Process\n",
    "* ordered_nodes -> list of nodes\n",
    "* select gapes between nodes\n",
    "* split gapes into whitespaces/newlines/etc and keywords/operators\n",
    "* create one list with all elements - nodes, whitespaces/newlines/etc, keywords/operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+\n",
      "import { types } from ./redux;\n",
      "\n",
      "export { default } from ./Profile.jsx;\n",
      "\n",
      "export const routes = {\n",
      "  [types.onRouteProfile]: /:username\n",
      "};\n",
      "\n",
      "-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+-=+\n",
      "import { types } from './redux';\n",
      "\n",
      "export { default } from './Profile.jsx';\n",
      "\n",
      "export const routes = {\n",
      "  [types.onRouteProfile]: '/:username'\n",
      "};\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lookout.style.format import reserved\n",
    "\n",
    "res = extract_nodes(contents[n], uasts[n], reserved.javascript.TOKENS)\n",
    "new_res = []\n",
    "for i in res:\n",
    "    if isinstance(i.node, str):\n",
    "        new_res.append(i.node)\n",
    "    else:\n",
    "        new_res.append(i.node.token)\n",
    "print(\"-=+\" * 20)\n",
    "print(\"\".join(new_res))\n",
    "print(\"-=+\" * 20)\n",
    "print(contents[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import common\n",
    "reload(common)\n",
    "\n",
    "\n",
    "Node, prepare_nodes, transform_content = common.WrappedNode, common.prepare_nodes, common.transform_content\n",
    "extract_nodes = common.extract_nodes\n",
    "collect_unique_features = common.collect_unique_features\n",
    "extract_features = common.extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"min_samples_split\": 40, \"min_samples_leaf\": 40,\n",
    "          \"criterion\": \"gini\"}\n",
    "\n",
    "\n",
    "def train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, seq_len=5, depth=5,\n",
    "                   use_parents=True):\n",
    "    features, labels, metadata = extract_features(\n",
    "        final_files, contents, uasts, seq_len=seq_len, use_features_after=use_features_after,\n",
    "        depth=depth, use_parents=use_parents, reserved_tokens=reserved.javascript.TOKENS)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    print(\"Features shape:\", features.shape)\n",
    "    X_tr, X_val, y_tr, y_val, meta_tr, meta_val = train_test_split(features, labels, metadata, random_state=1989)\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier(**dt_params)\n",
    "\n",
    "    clf = clf.fit(X_tr, y_tr)\n",
    "\n",
    "    print(\"train:\", accuracy_score(clf.predict(X_tr), y_tr))\n",
    "    print(\"val:\", accuracy_score(clf.predict(X_val), y_val))\n",
    "    \n",
    "    data = {\"X_tr\": X_tr, \"X_val\": X_val, \"y_tr\": y_tr, \"y_val\": y_val, \"meta_tr\": meta_tr,\n",
    "            \"meta_val\": meta_val, \"features\": features, \"labels\": labels, \n",
    "            \"metadata\": metadata}\n",
    "    \n",
    "    l_cnter = defaultdict(int)\n",
    "    for l in labels:\n",
    "        l_cnter[l] += 1\n",
    "    print(l_cnter)\n",
    "    return clf, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163it [00:01, 84.67it/s] \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "token_to_seq: `short]` != `shortId]`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4fb24a995ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muasts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_features_after\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-08292444f627>\u001b[0m in \u001b[0;36mtrain_pipeline\u001b[0;34m(final_files, contents, uasts, dt_params, use_features_after, seq_len, depth, use_parents)\u001b[0m\n\u001b[1;32m      7\u001b[0m     features, labels, metadata = extract_features(\n\u001b[1;32m      8\u001b[0m         \u001b[0mfinal_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muasts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_features_after\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_features_after\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         depth=depth, use_parents=use_parents, reserved_tokens=reserved.javascript.TOKENS)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/style-analyzer/lookout/style/format/research/common.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(filenames, contents, uasts, reserved_tokens, seq_len, depth, unique_features, use_features_after, use_parents)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \"\"\"\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munique_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0munique_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_unique_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muasts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserved_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreserved_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m     \u001b[0mfeature2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/style-analyzer/lookout/style/format/research/common.py\u001b[0m in \u001b[0;36mcollect_unique_features\u001b[0;34m(contents, uasts, reserved_tokens)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0munique_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# dummy counter for default reserved tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muast\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muasts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserved_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/style-analyzer/lookout/style/format/research/common.py\u001b[0m in \u001b[0;36mextract_nodes\u001b[0;34m(content, uast, reserved_tokens)\u001b[0m\n\u001b[1;32m    295\u001b[0m             res = split_whitespaces_reserved_to_nodes(\n\u001b[1;32m    296\u001b[0m                 \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_line\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0mcommon_anc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon_anc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserved_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreserved_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             )\n\u001b[1;32m    299\u001b[0m             \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/style-analyzer/lookout/style/format/research/common.py\u001b[0m in \u001b[0;36msplit_whitespaces_reserved_to_nodes\u001b[0;34m(start, start_line, start_col, end, common_anc, content, reserved_tokens)\u001b[0m\n\u001b[1;32m    245\u001b[0m                                         reserved_tokens):\n\u001b[1;32m    246\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_whitespaces_reserved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserved_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreserved_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/style-analyzer/lookout/style/format/research/common.py\u001b[0m in \u001b[0;36msplit_whitespaces_reserved\u001b[0;34m(text, reserved_tokens)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserved_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mel1_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mel2_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/style-analyzer/lookout/style/format/research/common.py\u001b[0m in \u001b[0;36mtoken_to_seq\u001b[0;34m(token, to_check)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"token_to_seq: `%s` != `%s`\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: token_to_seq: `short]` != `shortId]`"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, seq_len=5, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 31.39it/s]\n",
      "187it [00:19,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (268367, 40)\n",
      "train: 0.9454378338094647\n",
      "val: 0.9406039468192929\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=False, seq_len=5, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 31.51it/s] \n",
      "187it [00:12, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (268367, 20)\n",
      "train: 0.9834902496584276\n",
      "val: 0.9823078757526977\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, use_parents=False,\n",
    "                   seq_len=5, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 32.33it/s]\n",
      "187it [00:10, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (269859, 6)\n",
      "train: 0.9650829570046543\n",
      "val: 0.9630771511153932\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, use_parents=True,\n",
    "                   seq_len=1, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 33.80it/s] \n",
      "187it [00:12, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (269485, 16)\n",
      "train: 0.98478079094368\n",
      "val: 0.983346197233272\n",
      "defaultdict(<class 'int'>, {0: 175905, 1: 75575, 2: 9920, 3: 4175, 4: 3910})\n"
     ]
    }
   ],
   "source": [
    "clf, data = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, \n",
    "                           use_parents=True, seq_len=2, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:05, 33.73it/s] \n",
      "187it [00:10, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (269485, 8)\n",
      "train: 0.9844245545808533\n",
      "val: 0.9830196520809832\n",
      "defaultdict(<class 'int'>, {0: 175905, 1: 75575, 2: 9920, 3: 4175, 4: 3910})\n"
     ]
    }
   ],
   "source": [
    "_ = train_pipeline(final_files, contents, uasts, dt_params=params, use_features_after=True, \n",
    "                           use_parents=False, seq_len=2, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tl;Dr - couple of tokens before & after prediction spot + parent info gives the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc519cca908>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACVxJREFUeJzt3U+InPUdx/HPp9s1MVgQNQebXRoPIgShCSzBkltAjH/Q\nq4KehL1UiCCIHnoQ7+LFS1CxoCiCHkQsEmpERBuNGoMxKkEsRoTYiKiFrkn89LBzSK3dedbOb555\n8n2/YGFnMzz5EPbtMzM7PuskAlDLr/oeAGD6CB8oiPCBgggfKIjwgYIIHyhoEOHb3mP7Y9vHbd/X\n955xbD9u+6TtD/re0pXtRdsHbH9o+6jtvX1vWovtjbbfsv3+aO8DfW/qyvac7fdsv9jXhpkP3/ac\npEckXS9pm6TbbG/rd9VYT0ja0/eIdToj6Z4k2yRdI+mPM/7vvCJpd5LfS9ouaY/ta3re1NVeScf6\nHDDz4UvaKel4kk+T/CDpGUm39LxpTUlek/R13zvWI8mXSd4dff6dVr8xt/S76n/Lqu9HN+dHHzP/\nbjTbC5JulPRonzuGEP4WSZ+fc/uEZvgb8nxge6ukHZIO9rtkbaOHzIclnZS0P8lM7x15WNK9kn7s\nc8QQwscU2b5I0nOS7k7ybd971pLkbJLtkhYk7bR9dd+b1mL7Jkknk7zT95YhhP+FpMVzbi+MvoYJ\nsz2v1eifSvJ833u6SvKNpAOa/ddVdkm62fZnWn3Kutv2k30MGUL4b0u60vYVti+QdKukF3redN6x\nbUmPSTqW5KG+94xje7Pti0efXyjpWkkf9btqbUnuT7KQZKtWv49fSXJ7H1tmPvwkZyTdJellrb7g\n9GySo/2uWpvtpyW9Kekq2yds39n3pg52SbpDq2ehw6OPG/oetYbLJR2wfUSrJ4f9SXr78djQmP8t\nF6hn5s/4ACaP8IGCCB8oiPCBgggfKGhQ4dte7nvDeg1t89D2SsPbPAt7BxW+pN7/wX6BoW0e2l5p\neJt73zu08AFMQJM38Fx2yVy2Ls5P/LhfnTqrzZfOTfy4kvTJkU1NjntaK5rXhibHbmFoe6XhbW65\n91/6p37Iisfd79ct/vKti/N66+XF8XecIdf9dnvfE4D/28H8tdP9eKgPFET4QEGEDxRE+EBBhA8U\nRPhAQYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFET4QEGEDxRE+EBBhA8U1Cl823tsf2z7uO37Wo8C\n0NbY8G3PSXpE0vWStkm6zfa21sMAtNPljL9T0vEknyb5QdIzkm5pOwtAS13C3yLp83Nunxh97T/Y\nXrZ9yPahr06dndQ+AA1M7MW9JPuSLCVZanUJbACT0SX8LySde63shdHXAAxUl/DflnSl7StsXyDp\nVkkvtJ0FoKWxv1AjyRnbd0l6WdKcpMeTHG2+DEAznX6TTpKXJL3UeAuAKeGde0BBhA8URPhAQYQP\nFET4QEGEDxRE+EBBhA8URPhAQYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFNTpQhzr9cmRTbpuy44W\nh27m8z/9oe8J67L44Bt9T8CAccYHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcK\nInygIMIHCiJ8oCDCBwoifKAgwgcKInygoLHh237c9knbH0xjEID2upzxn5C0p/EOAFM0Nvwkr0n6\negpbAEwJz/GBgiZ2eW3by5KWJWmjNk3qsAAamNgZP8m+JEtJlua1YVKHBdAAD/WBgrr8OO9pSW9K\nusr2Cdt3tp8FoKWxz/GT3DaNIQCmh4f6QEGEDxRE+EBBhA8URPhAQYQPFET4QEGEDxRE+EBBhA8U\nRPhAQYQPFET4QEGEDxRE+EBBhA8URPhAQRO7yu5/SZoduoXFB9/oe8K6zF16Sd8T1u3sKX49w6zg\njA8URPhAQYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFET4QEGEDxRE+EBBhA8URPhAQYQPFET4QEGE\nDxRE+EBBY8O3vWj7gO0PbR+1vXcawwC00+Wae2ck3ZPkXdu/kfSO7f1JPmy8DUAjY8/4Sb5M8u7o\n8+8kHZO0pfUwAO2s6zm+7a2Sdkg62GIMgOnofHlt2xdJek7S3Um+/Zk/X5a0LEkbtWliAwFMXqcz\nvu15rUb/VJLnf+4+SfYlWUqyNK8Nk9wIYMK6vKpvSY9JOpbkofaTALTW5Yy/S9IdknbbPjz6uKHx\nLgANjX2On+R1SZ7CFgBTwjv3gIIIHyiI8IGCCB8oiPCBgggfKIjwgYIIHyiI8IGCCB8oiPCBgggf\nKIjwgYIIHyiI8IGCCB8oqPPFNjFbzp76uu8J6+YNw7sWY1ZW+p7QBGd8oCDCBwoifKAgwgcKInyg\nIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHCiJ8oCDCBwoifKAgwgcKInygIMIHChobvu2Ntt+y/b7t\no7YfmMYwAO10uebeiqTdSb63PS/pddt/SfK3xtsANDI2/CSR9P3o5vzoIy1HAWir03N823O2D0s6\nKWl/koNtZwFoqVP4Sc4m2S5pQdJO21f/9D62l20fsn3otM7PSxID54t1vaqf5BtJByTt+Zk/25dk\nKcnSvIZ3/XSgki6v6m+2ffHo8wslXSvpo9bDALTT5VX9yyX92facVv9D8WySF9vOAtBSl1f1j0ja\nMYUtAKaEd+4BBRE+UBDhAwURPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMFET5QEOEDBRE+UBDh\nAwURPlAQ4QMFdbn0FjARWRne1Zc9f0HfE9bntDvdjTM+UBDhAwURPlAQ4QMFET5QEOEDBRE+UBDh\nAwURPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMFET5QEOEDBXUO3/ac7fdsv9hyEID21nPG3yvp\nWKshAKanU/i2FyTdKOnRtnMATEPXM/7Dku6V9GPDLQCmZGz4tm+SdDLJO2Put2z7kO1DpzW8yygD\nlXQ54++SdLPtzyQ9I2m37Sd/eqck+5IsJVma14YJzwQwSWPDT3J/koUkWyXdKumVJLc3XwagGX6O\nDxS0rl+hleRVSa82WQJgajjjAwURPlAQ4QMFET5QEOEDBRE+UBDhAwURPlAQ4QMFET5QEOEDBRE+\nUBDhAwURPlAQ4QMFET5QEOEDBTnJ5A9qfyXp7xM/sHSZpH80OG5LQ9s8tL3S8Da33Pu7JJvH3alJ\n+K3YPpRkqe8d6zG0zUPbKw1v8yzs5aE+UBDhAwUNLfx9fQ/4BYa2eWh7peFt7n3voJ7jA5iMoZ3x\nAUwA4QMFET5QEOEDBRE+UNC/AWZc85xe958nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc50a594cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(data[\"y_val\"], clf.predict(data[\"X_val\"]))\n",
    "\n",
    "matshow(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        nope       0.99      0.99      0.99     43877\n",
      "  whitespace       0.98      0.98      0.98     19039\n",
      "     newline       0.93      0.94      0.94      2402\n",
      "newline_incr       0.91      0.83      0.87      1027\n",
      "newline_decr       0.87      0.80      0.83      1027\n",
      "\n",
      " avg / total       0.98      0.98      0.98     67372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [\"nope\", \"whitespace\", \"newline\", \"newline_incr\", \"newline_decr\"]\n",
    "print(classification_report(data[\"y_val\"], clf.predict(data[\"X_val\"]), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_proba = clf.predict_proba(data[\"X_val\"])\n",
    "max_pred = np.argmax(predictions_proba, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(data[\"X_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67372,)\n"
     ]
    }
   ],
   "source": [
    "max_predictions = predictions_proba[np.arange(max_pred.shape[0]), max_pred]\n",
    "print(max_predictions.shape)\n",
    "sorted_ind = np.argsort(max_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITE = \"\\033[0m\"\n",
    "RED = \"\\033[31m\"\n",
    "GREEN = \"\\033[32m\"\n",
    "ORANGE = \"\\033[33m\"\n",
    "BLUE = \"\\033[34m\"\n",
    "PURPLE = \"\\033[35m\"\n",
    "\n",
    "\n",
    "def visualize_content(meta, context_chars=100):\n",
    "    file, start, end, l_start, l_end = meta\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # surrounding context\n",
    "    print(content[max(0, start - context_chars):start], end=\"\")\n",
    "    # context before label\n",
    "    cprint(content[start:l_start], \"red\", \"on_white\", end=\"\")\n",
    "    # label\n",
    "    cprint(content[l_start:l_end], \"blue\", \"on_yellow\", end=\"\")\n",
    "    # context after label\n",
    "    cprint(content[l_end:end], \"red\", \"on_white\", end=\"\")\n",
    "    # surrounding context\n",
    "    print(content[end:min(len(content), end + context_chars)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m\u001b[31masdas\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored, cprint\n",
    "cprint(\"asdas\", \"red\", \"on_green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('/home/egor/workspace/tmp/freeCodeCamp/common/models/user.js',\n",
       "  21932,\n",
       "  21946,\n",
       "  21934,\n",
       "  21941),\n",
       " 'newline',\n",
       " 'whitespace')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = sorted_ind[0]\n",
    "data[\"meta_val\"][n], target_names[data[\"y_val\"][n]], target_names[predictions[n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateData.$push.progressTimestamps = {\n",
      "            $each: points.map(() => Date.now())\n",
      "          };\n",
      "        }\n",
      "        return this.update$(updateData);\n",
      "      })\n",
      "      .doOnNext(() => this.manualReload()\u001b[47m\u001b[31m )\u001b[0m\u001b[43m\u001b[34m\n",
      "      \u001b[0m\u001b[47m\u001b[31m.map(\u001b[0m() => dedent`\n",
      "        Your projects have been updated.\n",
      "      `);\n",
      "  };\n",
      "\n",
      "  User.prototype.updateMyProfileUI = function updateMyProfileUI(profileUI) {\n",
      "    const oldUI = { ...this.profileUI };\n",
      "    const u\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/egor/workspace/tmp/freeCodeCamp/server/boot/challenge.js', 7181, 7197, 7189, 7194) GT newline_decr , pred whitespace\n"
     ]
    }
   ],
   "source": [
    "n = sorted_ind[1]\n",
    "print(data[\"meta_val\"][n], \"GT\", target_names[data[\"y_val\"][n]], \", pred\", target_names[predictions[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate.now();\n",
      "\n",
      "    if (\n",
      "      !completedChallenge.solution ||\n",
      "      // only basejumps require github links\n",
      "      (\n",
      "        completedChallenge.challengeType === 4 &&\n",
      "        !completedChallenge.githubLink\u001b[47m\u001b[31m\n",
      "      )\u001b[0m\u001b[43m\u001b[34m\n",
      "    \u001b[0m\u001b[47m\u001b[31m) {\u001b[0m\n",
      "      req.flash(\n",
      "        'danger',\n",
      "        'You haven\\'t supplied the necessary URLs for us to inspect your work.'\n",
      "      );\n",
      "      return res.sendStatus(403);\n",
      "    }\n",
      "\n",
      "\n",
      "    return user.getCompletedChall\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/egor/workspace/tmp/freeCodeCamp/server/boot/certificate.js', 5495, 5507, 5501, 5504) GT newline_decr , pred whitespace\n"
     ]
    }
   ],
   "source": [
    "n = sorted_ind[2]\n",
    "print(data[\"meta_val\"][n], \"GT\", target_names[data[\"y_val\"][n]], \", pred\", target_names[predictions[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms.username}/legacy-data-visualization`\n",
      "    )\n",
      "  );\n",
      "\n",
      "  router.get(\n",
      "    '/:username/back-end-certification',\n",
      "    (req, res) => res.redirect(\n",
      "      `/certification/${req.params.username}/legacy-back-end`\u001b[47m\u001b[31m\n",
      "    )\u001b[0m\u001b[43m\u001b[34m\n",
      "  \u001b[0m\u001b[47m\u001b[31m);\n",
      "\u001b[0m\n",
      "  router.get(\n",
      "    '/:username/full-stack-certification',\n",
      "    (req, res) => res.redirect(\n",
      "      `/certification/${req.params.username}/legacy-full-stack`\n",
      "    )\n",
      "  );\n",
      "\n",
      "  router.post(\n",
      "    '/certificate/v\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/egor/workspace/tmp/freeCodeCamp/common/app/Flash/redux/index.js', 1094, 1121, 1103, 1114) GT nope , pred newline\n"
     ]
    }
   ],
   "source": [
    "n = sorted_ind[100]\n",
    "print(data[\"meta_val\"][n], \"GT\", target_names[data[\"y_val\"][n]], \", pred\", target_names[predictions[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      [types.clickOnClose]: _.tail,\n",
      "      [types.fetchMessages.complete]: (state, { payload }) => [\n",
      "        ...state,\n",
      "        ...utils.expressToStack(payload)\n",
      "      ]\n",
      "    }),\n",
      "    defaultState,\n",
      "  ),\n",
      "  \u001b[47m\u001b[31mfunction \u001b[0m\u001b[43m\u001b[34mmetaReducer\u001b[0m\u001b[47m\u001b[31m(state \u001b[0m= defaultState, action) {\n",
      "    if (utils.isFlashAction(action)) {\n",
      "      const { payload } = utils.getFlashAction(action);\n",
      "      return [\n",
      "        ...state,\n",
      "        ...payload\n",
      "      ];\n",
      "    }\n",
      "    return s\n"
     ]
    }
   ],
   "source": [
    "visualize_content(data[\"meta_val\"][n], context_chars=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
